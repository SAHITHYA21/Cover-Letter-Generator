{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58854896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eeb101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first person to land on the moon was Neil Armstrong. He stepped out of the lunar module Eagle and onto the moon's surface on July 20, 1969, during the Apollo 11 mission. Armstrong famously declared, \"That's one small step for man, one giant leap for mankind,\" as he became the first human to set foot on the moon.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    groq_api_key='API_KEY'\n",
    ")\n",
    "response = llm.invoke(\"The first person to land on moon was ...\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51733660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Software Engineer II, Platform\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main content\n",
      "Open Virtual Assistant\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home\n",
      "\n",
      "\n",
      "Career Areas\n",
      "\n",
      "\n",
      "Total Rewards\n",
      "\n",
      "\n",
      "Life@Nike\n",
      "\n",
      "\n",
      "Purpose\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Language\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Select a Language\n",
      "\n",
      "  Deutsch  \n",
      "  English  \n",
      "  Español (España)  \n",
      "  Español (América Latina)  \n",
      "  Français  \n",
      "  Italiano  \n",
      "  Nederlands  \n",
      "  Polski  \n",
      "  Tiếng Việt  \n",
      "  Türkçe  \n",
      "  简体中文  \n",
      "  繁體中文  \n",
      "  עִברִית  \n",
      "  한국어  \n",
      "  日本語  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Close Menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chat\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                Home\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "                                Career Areas\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "                                Total Rewards\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "                                Life@Nike\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "                                Purpose\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jordan Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Converse Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Language\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menu\n",
      "\n",
      "\n",
      "\n",
      "Return to Previous Menu\n",
      "\n",
      "\n",
      "\n",
      "Select a Language\n",
      "\n",
      "  Deutsch  \n",
      "  English  \n",
      "  Español (España)  \n",
      "  Español (América Latina)  \n",
      "  Français  \n",
      "  Italiano  \n",
      "  Nederlands  \n",
      "  Polski  \n",
      "  Tiếng Việt  \n",
      "  Türkçe  \n",
      "  简体中文  \n",
      "  繁體中文  \n",
      "  עִברִית  \n",
      "  한국어  \n",
      "  日本語  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        Back to Search\n",
      "\n",
      "                    \n",
      "\n",
      "Software Engineer II, Platform\n",
      "\n",
      "\n",
      "Categories ID\n",
      "\n",
      "\n",
      "\n",
      "Categories URL\n",
      "\n",
      "\n",
      "\n",
      "Position Type\n",
      "Full Time\n",
      "\n",
      "\n",
      "Date Posted\n",
      "\n",
      "\n",
      "\n",
      "Primary Quest ID\n",
      "\n",
      "\n",
      "\n",
      "Second Quest ID\n",
      "\n",
      "\n",
      "\n",
      "Job Classification\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Career area\n",
      "Software Engineering\n",
      "\n",
      "\n",
      "Location\n",
      "1 Bowerman Drive, Beaverton, Oregon 97005, United States\n",
      "\n",
      "\n",
      "\n",
      "Job ID\n",
      "R-62064\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            Apply Now\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share Job\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share Job Posting\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Facebook\n",
      "Opens In A New Tab\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn\n",
      "Link Opens In New Window\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Email\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Close-Medium (Default Size)-icon\n",
      "\n",
      "Close Menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Become a Part of the NIKE, Inc. Team\n",
      "NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore\n",
      "                            potential, obliterate boundaries\n",
      "                            and push out the edges of what can be. The company looks for people who can grow, think,\n",
      "                            dream and create. Its\n",
      "                            culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers,\n",
      "                            leaders and\n",
      "                            visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a\n",
      "                            challenging and constantly\n",
      "                            evolving game.\n",
      "\n",
      "WHO YOU’LL WORK WITHA Platform Engineer in the NRTD team develops and operates foundational platforms using modern technologies, with an emphasis on innovation, performance, and stability. The role involves working alongside senior engineers to create scalable and resilient platforms that efficiently handle high-throughput data. Additionally, you will collaborate with product owners, cross-functional teams, and customer engineering teams to develop platforms, SDKs, and tools in the streaming domain, in line with NIKE's strategic objectives.WHO WE ARE LOOKING FORThe candidate plays an integral role in developing and sustaining real-time data streaming systems with dedication and a problem-solving attitude. A robust foundation in AWS cloud infrastructure, programming, and CI/CD practices is advantageous, coupled with a commitment to continuous skill enhancement. The candidate should demonstrate a keen interest in advancing their knowledge of cloud infrastructure, distributed systems, and stream processing technologies. Collaboration with senior team members is essential for the development of scalable, resilient platforms that efficiently manage high-throughput data streams.The candidate should have the following:Bachelor's degree in computer science, software engineering or related field. Will accept any suitable combination of education, experience and training.2+ years of relevant experience.Experience designing, developing, and testing services using Java, Python, Golang, or Node.js.Experience building RESTful microservices utilizing AWS services (S3, Route 53, ELB/ALBs, SQS/SNS).Experience with Docker and Kubernetes for containerization and deployment.Familiarity with streaming technologies such as Kafka, Pulsar, Spark Streaming, Flink.Proficiency with SQL or NoSQL databases.Strong knowledge of continuous integration, unit testing, static analysis, and automated integration tests. Continuous delivery experience preferred.Good understanding of Scrum and agile principles.Excellent verbal and written communication skills to work with both business and technical teams.WHAT YOU’LL WORK ONYou will collaborate with the Platform team to develop solutions tailored to customer needs. Your responsibilities include analyzing customer requirements, providing technical guidance, and coordinating with product owners to build solutions. Furthermore, you will integrate standard foundational platforms to enhance operational efficiency. Under the team's technical leadership, you will implement designs that meet customer requirements and construct microservices, deploying them within the Kubernetes ecosystem. You will also engage in various sprint ceremonies such as backlog grooming, estimation, development, demos and retrospectives.You will:Assist in building and maintaining streaming pipelines using Kafka and other technologies.Support cloud infrastructure development on AWS platform.Monitor system performance and troubleshoot streaming issues to ensure reliability and efficiency.Collaborate with senior engineers and cross-functional teams to improve platform scalability and resilience.Contribute to automation efforts by enhancing CI/CD workflows and infrastructure-as-code practices.Optimize data streaming solutions for low-latency, high-throughput processing.Write and maintain technical documentation to support system improvements and knowledge sharing.Engage in continuous learning, staying up to date with emerging trends in cloud computing and streaming technology.Participate in team discussions and code reviews to refine skills and contribute to best practices.Approach challenges with curiosity and a problem-solving mindset to drive innovation and efficiency.We offer a number of accommodations to complete our interview process including screen readers, sign language interpreters, accessible and single location for in-person interviews, closed captioning, and other reasonable modifications as needed. If you discover, as you navigate our application process, that you need assistance or an accommodation due to a disability, please complete the Candidate Accommodation Request Form.\n",
      "\n",
      "NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a\n",
      "                            generous total rewards\n",
      "                            package, casual work environment, a diverse and inclusive culture, and an electric\n",
      "                            atmosphere for professional\n",
      "                            development. No matter the location, or the role, every Nike employee shares one galvanizing\n",
      "                            mission: To bring\n",
      "                            inspiration and innovation to every athlete* in the world.\n",
      "NIKE, Inc. is an equal opportunity employer. Qualified applicants will receive\n",
      "                            consideration without\n",
      "                            regard to race, color, religion, sex, national origin, age, sexual orientation, gender\n",
      "                            identity, gender expression,\n",
      "                            veteran status, or disability.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                Apply Now\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share Job\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Share Job Posting\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Faceboox\n",
      "Opens In A New Tab\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinkedIn\n",
      "Link Opens In New Window\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Email\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Close-Medium (Default Size)-icon\n",
      "\n",
      "Close Menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What You Can Expect\n",
      "OUR HIRING GAME PLAN\n",
      "\n",
      "\n",
      "01 Apply\n",
      "Our teams are made up of diverse skillsets, knowledge bases, inputs, ideas and backgrounds.\n",
      "                            We want you to find your fit – review job descriptions, departments and teams to discover\n",
      "                            the role for you.\n",
      "\n",
      "\n",
      "02 Meet a Recruiter or Take an Assessment\n",
      "If selected for a corporate role, a recruiter will reach out to start your interview process\n",
      "                            and be your main contact\n",
      "                            throughout the process. For retail roles, you’ll complete an interactive assessment that\n",
      "                            includes a chat and quizzes and\n",
      "                            takes about 10-20 minutes to complete.  No matter the role, we want to learn about you – the\n",
      "                            whole you – so don’t shy\n",
      "                            away from how you approach world-class service and what makes you unique.\n",
      "\n",
      "\n",
      "03 Interview\n",
      "Go into this stage confident by doing your research, understanding what we are looking for\n",
      "                            and being prepared for\n",
      "                            questions that are set up to learn more about you, and your background.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home\n",
      "\n",
      "\n",
      "About Us\n",
      "\n",
      "\n",
      "Contact\n",
      "\n",
      "\n",
      "Talent Community\n",
      "\n",
      "\n",
      "Terms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              \n",
      "                   \n",
      "                    Nike Applicant Privacy Policy\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We offer a number of accommodations to complete our interview process including screen readers, sign language interpreters,\n",
      "                accessible and single location for in-person interviews, closed captioning, and other reasonable modifications as\n",
      "                needed.\n",
      "\n",
      "\n",
      "If you discover, as you navigate our application process, that you need assistance or an accommodation due to a\n",
      "                disability, please contact us at +1 503-671-4156 and include your full name, best way to reach you, and the\n",
      "                accommodation you request to assist with the application process.\n",
      "For more information, please refer to Equal Employment\n",
      "                        Opportunity is The Law.\n",
      "\n",
      "\n",
      "\n",
      "©  Nike, Inc. All Rights Reserved\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chat\n",
      "Chat with our AI Assistant\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://careers.nike.com/software-engineer-ii-platform/job/R-62064\")\n",
    "page_data = loader.load().pop().page_content\n",
    "print(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "979e9a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Software Engineer II, Platform\": {\n",
      "    \"role\": \"Software Engineer II, Platform\",\n",
      "    \"experience\": {\n",
      "      \"required\": \"2+ years of relevant experience\",\n",
      "      \"degree\": \"Bachelor's degree in computer science, software engineering or related field\"\n",
      "    },\n",
      "    \"skills\": [\n",
      "      \"Java, Python, Golang, or Node.js\",\n",
      "      \"AWS services (S3, Route 53, ELB/ALBs, SQS/SNS)\",\n",
      "      \"Docker and Kubernetes for containerization and deployment\",\n",
      "      \"streaming technologies such as Kafka, Pulsar, Spark Streaming, Flink\",\n",
      "      \"SQL or NoSQL databases\",\n",
      "      \"continuous integration, unit testing, static analysis, and automated integration tests\",\n",
      "      \"Scrum and agile principles\"\n",
      "    ],\n",
      "    \"description\": \"The candidate plays an integral role in developing and sustaining real-time data streaming systems with dedication and a problem-solving attitude. A robust foundation in AWS cloud infrastructure, programming, and CI/CD practices is advantageous, coupled with a commitment to continuous skill enhancement.\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm\n",
    "res= chain_extract.invoke(input={\"page_data\": page_data})\n",
    "print(res.content)\n",
    "type(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd41d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Software Engineer II, Platform': {'role': 'Software Engineer II, Platform',\n",
       "  'experience': {'required': '2+ years of relevant experience',\n",
       "   'degree': \"Bachelor's degree in computer science, software engineering or related field\"},\n",
       "  'skills': ['Java, Python, Golang, or Node.js',\n",
       "   'AWS services (S3, Route 53, ELB/ALBs, SQS/SNS)',\n",
       "   'Docker and Kubernetes for containerization and deployment',\n",
       "   'streaming technologies such as Kafka, Pulsar, Spark Streaming, Flink',\n",
       "   'SQL or NoSQL databases',\n",
       "   'continuous integration, unit testing, static analysis, and automated integration tests',\n",
       "   'Scrum and agile principles'],\n",
       "  'description': 'The candidate plays an integral role in developing and sustaining real-time data streaming systems with dedication and a problem-solving attitude. A robust foundation in AWS cloud infrastructure, programming, and CI/CD practices is advantageous, coupled with a commitment to continuous skill enhancement.'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_res= json_parser.parse(res.content)\n",
    "json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b246196a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d5d70c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Sahithya Arveti Nagaraju\",\n",
      "  \"education\": [\n",
      "    \"University at Buffalo (GPA 3.97/4.00) Jan. 2024 – May 2025 Master of Science in Data Science Buffalo, New York\",\n",
      "    \"Siddaganga Institute of Technology (CGPA 9.44/10.00) Aug. 2017 – Jun. 2021 Bachelor of Science in Information Science and Engineering India\"\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    \"Graduate Teaching Assistant at University at Buffalo Jan 2025 - May 2025 Buffalo, NY, United States Collaborated with Professor Khinkis on refining lecture materials for advanced statistical methods and data mining (using R), incorporating real-world case studies that improved student comprehension scores by 15% according to course evaluations.\",\n",
      "    \"Software Engineer II at Sabre Aug 2021 – Jan 2024 Bengaluru, India Migrated GetThere services from legacy web servers to Google Cloud Platform using Terraform, Docker, and Kubernetes, improving scalability, optimizing traffic, and cutting infrastructure costs by 22%.\",\n",
      "    \"Software Engineer (Intern) at Sabre Jan 2021 – July 2021 Bengaluru, India Created a ServiceNow API based application using Python (Flask) and Jenkins to automate change record submissions, resulting in a 60% reduction in manual processing time.\",\n",
      "    \"Research Intern at Samsung PRISM Aug 2020 - Aug 2021 India Designed and trained an LSTM-based neural machine translation model to convert Hindi to English using TensorFlow and Keras, achieving a BLEU score of 0.97.\"\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    \"Cloud-Native ETL Pipeline | Data Warehouse, Databricks, Snowflake, Airflow, Python, Docker, SQL Mar 2025 Built an automated ETL pipeline using Snowflake’s TPC-H dataset, modular dbt models, and Apache Airflow DAGs to support scalable transformation workflows.\",\n",
      "    \"Real Estate Price Prediction | Python, SQLite3, numpy, scikit, MLFlow, Git, Digital Ocean, Docker, Streamlit Mar 2024 Built an end-to-end regression pipeline for predicting housing prices using scikit-learn models (like Regression, KNN, Random Forest), exploratory data analysis, and feature engineering.\",\n",
      "    \"Online Shopping System | Python (numpy, pandas, Faker), MySQL Nov 2024 Designed and deployed a scalable e-commerce relational database supporting 3,500+ users with <4ms query performance using optimized indexes, stored procedures, and CTEs.\",\n",
      "    \"A Predictive Assessment System for Diabetes Risk Factors | Python, PySpark, PySpark’s MLlib Nov 2024 Created a distributed machine learning workflow with PySpark MLlib to handle large medical datasets and train Logistic Regression and Gradient Boosted models, achieving 8% performance improvement and 40% reduction in execution time for risk prediction of diabetes.\",\n",
      "    \"Ollama Local LLM RAG | Python, Generative AI, LLM, Llama, RAG Aug 2024 Developed a local Retrieval-Augmented Generation (RAG) pipeline using Llama3 and mxbai-embed-large embeddings (1024-d) to enable intelligent PDF querying with 90% accuracy.\",\n",
      "    \"Bank Marketing Campaigns | Tableau, Data Visualization Jul 2024 Designed a Tableau dashboard to evaluate term deposit campaign performance, highlighting conversion patterns and segment-specific engagement, enabling decision-makers to forecast marketing outcomes and optimize targeting using interactive filters and historical trend visuals.\",\n",
      "    \"Web Portal for Activity Points | HTML, CSS, JavaScript, PHP, MySQL Aug 2020 Developed a responsive web portal to manage AICTE-mandated student activity points, integrating HTML/CSS, JavaScript, PHP, and MySQL to streamline data entry and score tracking for students and faculty.\"\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Programming Languages: Java, Python, Golang, R, MATLAB, Shell Scripting, C++, PHP, Data Structures, Algorithms, Object Oriented Programming\",\n",
      "    \"Database Management: MongoDB, PostgreSQL, MySQL, Hadoop, Spark, Pyspark, Sonwflake, Databricks\",\n",
      "    \"Machine Learning & Analytics: numPy, Pandas, scikit-learn, SQLite3, TensorFlow, PyTorch, Matplotlib\",\n",
      "    \"Cloud & DevOps: GCP, AWS, Kubernetes, Docker, Jenkins, Terraform\",\n",
      "    \"Data Visualization & Monitoring: Tableau, AppDynamics, Splunk, Grafana\",\n",
      "    \"Tools & Platforms: Excel, Linux, Unix, Kafka, GitHub, Bitbucket, Jira, ServiceNow, ElasticSearch\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        return \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "\n",
    "resume_struct_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### Resume Text:\n",
    "    {resume_text}\n",
    "\n",
    "    Extract the following details from the resume text below and format them as a JSON in this structure:\n",
    "\n",
    "    resume_data = {{\n",
    "        \"name\": \"<Full Name in string>\",\n",
    "        \"education\": [<list of education entries in list of strings for each degree>],\n",
    "        \"experience\": [\"<For each job, provide a single descriptive string combining company, position, duration, location, and key responsibilities/accomplishments>\"],\n",
    "        \"projects\": [<For each project, provide a single descriptive string summarizing the project title, technologies used, duration, and outcome or objective>],\n",
    "        \"skills\": [<list of skills in list of strings>]\n",
    "    }}\n",
    "    Only return the valid JSON.\n",
    "    ### VALID JSON (NO PREAMBLE): \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "pdf_path = \"Sahithya_ArvetiNagaraju.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "chain_extract_resume = resume_struct_prompt | llm\n",
    "resume_res= chain_extract_resume.invoke(input={\"resume_text\": resume_text})\n",
    "print(resume_res.content)\n",
    "type(resume_res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4c0cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Sahithya Arveti Nagaraju',\n",
       " 'education': ['University at Buffalo (GPA 3.97/4.00) Jan. 2024 – May 2025 Master of Science in Data Science Buffalo, New York',\n",
       "  'Siddaganga Institute of Technology (CGPA 9.44/10.00) Aug. 2017 – Jun. 2021 Bachelor of Science in Information Science and Engineering India'],\n",
       " 'experience': ['Graduate Teaching Assistant at University at Buffalo Jan 2025 - May 2025 Buffalo, NY, United States Collaborated with Professor Khinkis on refining lecture materials for advanced statistical methods and data mining (using R), incorporating real-world case studies that improved student comprehension scores by 15% according to course evaluations.',\n",
       "  'Software Engineer II at Sabre Aug 2021 – Jan 2024 Bengaluru, India Migrated GetThere services from legacy web servers to Google Cloud Platform using Terraform, Docker, and Kubernetes, improving scalability, optimizing traffic, and cutting infrastructure costs by 22%.',\n",
       "  'Software Engineer (Intern) at Sabre Jan 2021 – July 2021 Bengaluru, India Created a ServiceNow API based application using Python (Flask) and Jenkins to automate change record submissions, resulting in a 60% reduction in manual processing time.',\n",
       "  'Research Intern at Samsung PRISM Aug 2020 - Aug 2021 India Designed and trained an LSTM-based neural machine translation model to convert Hindi to English using TensorFlow and Keras, achieving a BLEU score of 0.97.'],\n",
       " 'projects': ['Cloud-Native ETL Pipeline | Data Warehouse, Databricks, Snowflake, Airflow, Python, Docker, SQL Mar 2025 Built an automated ETL pipeline using Snowflake’s TPC-H dataset, modular dbt models, and Apache Airflow DAGs to support scalable transformation workflows.',\n",
       "  'Real Estate Price Prediction | Python, SQLite3, numpy, scikit, MLFlow, Git, Digital Ocean, Docker, Streamlit Mar 2024 Built an end-to-end regression pipeline for predicting housing prices using scikit-learn models (like Regression, KNN, Random Forest), exploratory data analysis, and feature engineering.',\n",
       "  'Online Shopping System | Python (numpy, pandas, Faker), MySQL Nov 2024 Designed and deployed a scalable e-commerce relational database supporting 3,500+ users with <4ms query performance using optimized indexes, stored procedures, and CTEs.',\n",
       "  'A Predictive Assessment System for Diabetes Risk Factors | Python, PySpark, PySpark’s MLlib Nov 2024 Created a distributed machine learning workflow with PySpark MLlib to handle large medical datasets and train Logistic Regression and Gradient Boosted models, achieving 8% performance improvement and 40% reduction in execution time for risk prediction of diabetes.',\n",
       "  'Ollama Local LLM RAG | Python, Generative AI, LLM, Llama, RAG Aug 2024 Developed a local Retrieval-Augmented Generation (RAG) pipeline using Llama3 and mxbai-embed-large embeddings (1024-d) to enable intelligent PDF querying with 90% accuracy.',\n",
       "  'Bank Marketing Campaigns | Tableau, Data Visualization Jul 2024 Designed a Tableau dashboard to evaluate term deposit campaign performance, highlighting conversion patterns and segment-specific engagement, enabling decision-makers to forecast marketing outcomes and optimize targeting using interactive filters and historical trend visuals.',\n",
       "  'Web Portal for Activity Points | HTML, CSS, JavaScript, PHP, MySQL Aug 2020 Developed a responsive web portal to manage AICTE-mandated student activity points, integrating HTML/CSS, JavaScript, PHP, and MySQL to streamline data entry and score tracking for students and faculty.'],\n",
       " 'skills': ['Programming Languages: Java, Python, Golang, R, MATLAB, Shell Scripting, C++, PHP, Data Structures, Algorithms, Object Oriented Programming',\n",
       "  'Database Management: MongoDB, PostgreSQL, MySQL, Hadoop, Spark, Pyspark, Sonwflake, Databricks',\n",
       "  'Machine Learning & Analytics: numPy, Pandas, scikit-learn, SQLite3, TensorFlow, PyTorch, Matplotlib',\n",
       "  'Cloud & DevOps: GCP, AWS, Kubernetes, Docker, Jenkins, Terraform',\n",
       "  'Data Visualization & Monitoring: Tableau, AppDynamics, Splunk, Grafana',\n",
       "  'Tools & Platforms: Excel, Linux, Unix, Kafka, GitHub, Bitbucket, Jira, ServiceNow, ElasticSearch']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_resume= json_parser.parse(resume_res.content)\n",
    "resume_data = json_resume\n",
    "resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45febb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['1bdd017b-6166-47da-a9ed-3ec4e32e50f8',\n",
       "  'ebbdc4c6-cbba-4088-8c42-1ed74182347b',\n",
       "  '8f565320-ea04-4198-ba14-94a8f8215f27',\n",
       "  'f68ad19c-34a0-4ba9-bc67-d3497f1b96a4',\n",
       "  'a8ffe761-6e5b-412e-8d9a-fdd023ab3d25',\n",
       "  '37e7d312-c1f0-44e4-809d-e62a20c715e3',\n",
       "  '03e21e85-63fc-472f-b4ee-de496202310a',\n",
       "  '0f3daee6-5253-4900-8e19-f446393d5cc1',\n",
       "  'd21a3e1c-7776-4d35-9562-1e48928f0b0f',\n",
       "  '2da8396a-7f5e-4472-b1f9-cf165a50277a',\n",
       "  '2444028d-122a-4cdb-8043-b34c16b4b0d7',\n",
       "  'f1003110-935b-41a5-b0c7-d0fc802db47b',\n",
       "  '71ee3249-0b80-4ac7-bf78-2028e13c0c00',\n",
       "  '9eca13d4-d18e-4286-897d-31870959dce7',\n",
       "  '02ba72de-deca-46ad-b313-dc89285f2d19',\n",
       "  '837ded3c-ed0e-4511-bada-54bb67e55549',\n",
       "  '3d09ec01-b44d-4af4-8fa7-29584dff31d1',\n",
       "  '96324b12-671d-4232-ad31-d06fd856f4df',\n",
       "  '68c82fe8-32f0-49ee-80a0-8495fedbeff5',\n",
       "  '6fa672eb-4951-42e8-a792-2645924ff368'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Sahithya Arveti Nagaraju',\n",
       "  'University at Buffalo (GPA 3.97/4.00) Jan. 2024 – May 2025 Master of Science in Data Science Buffalo, New York',\n",
       "  'Siddaganga Institute of Technology (CGPA 9.44/10.00) Aug. 2017 – Jun. 2021 Bachelor of Science in Information Science and Engineering India',\n",
       "  'Graduate Teaching Assistant at University at Buffalo Jan 2025 - May 2025 Buffalo, NY, United States Collaborated with Professor Khinkis on refining lecture materials for advanced statistical methods and data mining (using R), incorporating real-world case studies that improved student comprehension scores by 15% according to course evaluations.',\n",
       "  'Software Engineer II at Sabre Aug 2021 – Jan 2024 Bengaluru, India Migrated GetThere services from legacy web servers to Google Cloud Platform using Terraform, Docker, and Kubernetes, improving scalability, optimizing traffic, and cutting infrastructure costs by 22%.',\n",
       "  'Software Engineer (Intern) at Sabre Jan 2021 – July 2021 Bengaluru, India Created a ServiceNow API based application using Python (Flask) and Jenkins to automate change record submissions, resulting in a 60% reduction in manual processing time.',\n",
       "  'Research Intern at Samsung PRISM Aug 2020 - Aug 2021 India Designed and trained an LSTM-based neural machine translation model to convert Hindi to English using TensorFlow and Keras, achieving a BLEU score of 0.97.',\n",
       "  'Cloud-Native ETL Pipeline | Data Warehouse, Databricks, Snowflake, Airflow, Python, Docker, SQL Mar 2025 Built an automated ETL pipeline using Snowflake’s TPC-H dataset, modular dbt models, and Apache Airflow DAGs to support scalable transformation workflows.',\n",
       "  'Real Estate Price Prediction | Python, SQLite3, numpy, scikit, MLFlow, Git, Digital Ocean, Docker, Streamlit Mar 2024 Built an end-to-end regression pipeline for predicting housing prices using scikit-learn models (like Regression, KNN, Random Forest), exploratory data analysis, and feature engineering.',\n",
       "  'Online Shopping System | Python (numpy, pandas, Faker), MySQL Nov 2024 Designed and deployed a scalable e-commerce relational database supporting 3,500+ users with <4ms query performance using optimized indexes, stored procedures, and CTEs.',\n",
       "  'A Predictive Assessment System for Diabetes Risk Factors | Python, PySpark, PySpark’s MLlib Nov 2024 Created a distributed machine learning workflow with PySpark MLlib to handle large medical datasets and train Logistic Regression and Gradient Boosted models, achieving 8% performance improvement and 40% reduction in execution time for risk prediction of diabetes.',\n",
       "  'Ollama Local LLM RAG | Python, Generative AI, LLM, Llama, RAG Aug 2024 Developed a local Retrieval-Augmented Generation (RAG) pipeline using Llama3 and mxbai-embed-large embeddings (1024-d) to enable intelligent PDF querying with 90% accuracy.',\n",
       "  'Bank Marketing Campaigns | Tableau, Data Visualization Jul 2024 Designed a Tableau dashboard to evaluate term deposit campaign performance, highlighting conversion patterns and segment-specific engagement, enabling decision-makers to forecast marketing outcomes and optimize targeting using interactive filters and historical trend visuals.',\n",
       "  'Web Portal for Activity Points | HTML, CSS, JavaScript, PHP, MySQL Aug 2020 Developed a responsive web portal to manage AICTE-mandated student activity points, integrating HTML/CSS, JavaScript, PHP, and MySQL to streamline data entry and score tracking for students and faculty.',\n",
       "  'Programming Languages: Java, Python, Golang, R, MATLAB, Shell Scripting, C++, PHP, Data Structures, Algorithms, Object Oriented Programming',\n",
       "  'Database Management: MongoDB, PostgreSQL, MySQL, Hadoop, Spark, Pyspark, Sonwflake, Databricks',\n",
       "  'Machine Learning & Analytics: numPy, Pandas, scikit-learn, SQLite3, TensorFlow, PyTorch, Matplotlib',\n",
       "  'Cloud & DevOps: GCP, AWS, Kubernetes, Docker, Jenkins, Terraform',\n",
       "  'Data Visualization & Monitoring: Tableau, AppDynamics, Splunk, Grafana',\n",
       "  'Tools & Platforms: Excel, Linux, Unix, Kafka, GitHub, Bitbucket, Jira, ServiceNow, ElasticSearch'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'section': 'name'},\n",
       "  {'section': 'education'},\n",
       "  {'section': 'education'},\n",
       "  {'section': 'experience'},\n",
       "  {'section': 'experience'},\n",
       "  {'section': 'experience'},\n",
       "  {'section': 'experience'},\n",
       "  {'section': 'projects'},\n",
       "  {'section': 'projects'},\n",
       "  {'section': 'projects'},\n",
       "  {'section': 'projects'},\n",
       "  {'section': 'projects'},\n",
       "  {'section': 'projects'},\n",
       "  {'section': 'projects'},\n",
       "  {'section': 'skills'},\n",
       "  {'section': 'skills'},\n",
       "  {'section': 'skills'},\n",
       "  {'section': 'skills'},\n",
       "  {'section': 'skills'},\n",
       "  {'section': 'skills'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import Runnable\n",
    "import json\n",
    "\n",
    "# --- Initialize ChromaDB ---\n",
    "client = chromadb.PersistentClient(path='vectorstore_resume')\n",
    "collection = client.get_or_create_collection(name=\"resume_data\")\n",
    "\n",
    "# --- Ingest each resume section ---\n",
    "if not collection.count():\n",
    "    for section, items in resume_data.items():\n",
    "        if isinstance(items, list):\n",
    "            for item in items:\n",
    "                collection.add(\n",
    "                    documents=[item],\n",
    "                    metadatas={\"section\": section},\n",
    "                    ids=[str(uuid.uuid4())]\n",
    "                )\n",
    "        else:\n",
    "            print(section, items)\n",
    "            collection.add(\n",
    "                documents=[items],\n",
    "                metadatas={\"section\": section},\n",
    "                ids=[str(uuid.uuid4())]\n",
    "            )\n",
    "\n",
    "collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d83db857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': []}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs=collection.get()\n",
    "all_docs\n",
    "collection.delete(ids=all_docs['ids'])\n",
    "collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db73484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Java, Python, Golang, or Node.js', 'AWS services (S3, Route 53, ELB/ALBs, SQS/SNS)', 'Docker and Kubernetes for containerization and deployment', 'streaming technologies such as Kafka, Pulsar, Spark Streaming, Flink', 'SQL or NoSQL databases', 'continuous integration, unit testing, static analysis, and automated integration tests', 'Scrum and agile principles']\n"
     ]
    }
   ],
   "source": [
    "job = json_res\n",
    "skills = job['Software Engineer II, Platform']['skills']\n",
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b2e217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'section': 'skills'}, {'section': 'skills'}],\n",
       " [{'section': 'skills'}, {'section': 'projects'}],\n",
       " [{'section': 'skills'}, {'section': 'projects'}],\n",
       " [{'section': 'skills'}, {'section': 'skills'}],\n",
       " [{'section': 'skills'}, {'section': 'skills'}],\n",
       " [{'section': 'experience'}, {'section': 'skills'}],\n",
       " [{'section': 'experience'}, {'section': 'education'}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = collection.query(query_texts=skills, n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aed7f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Software Engineer II, Platform position at your esteemed organization. With a strong foundation in developing and sustaining real-time data streaming systems, I am confident that my skills and experience make me an ideal fit for this role.\n",
      "\n",
      "As a seasoned software engineer with a proven track record of delivering high-impact projects, I am well-equipped to leverage my expertise in AWS cloud infrastructure, programming, and CI/CD practices to drive innovation and growth. My experience in migrating GetThere services from legacy web servers to Google Cloud Platform using Terraform, Docker, and Kubernetes has not only improved scalability but also optimized traffic and reduced infrastructure costs by 22%. I am eager to bring my expertise to a new challenge and contribute to the development and sustenance of real-time data streaming systems.\n",
      "\n",
      "In my previous role at Sabre, I successfully created a ServiceNow API-based application using Python (Flask) and Jenkins to automate change record submissions, resulting in a 60% reduction in manual processing time. This experience has taught me the importance of streamlining processes and leveraging technology to drive efficiency. I am excited to apply this knowledge and skillset to a new role and make a meaningful impact.\n",
      "\n",
      "I am particularly drawn to this role because of the emphasis on continuous skill enhancement and dedication to problem-solving. As a lifelong learner, I am committed to staying up-to-date with the latest technologies and trends in the industry. My proficiency in programming languages such as Java, Python, Golang, and C++, as well as my experience with tools like Kafka, GitHub, and Jira, make me well-suited to tackle complex challenges and drive results.\n",
      "\n",
      "I am confident that my unique blend of technical expertise, problem-solving skills, and passion for innovation make me an excellent fit for this role. I would welcome the opportunity to discuss my application and how I can contribute to the success of your team.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "skills = job['Software Engineer II, Platform']['skills']\n",
    "query = skills\n",
    "results = collection.query(query_texts=query, n_results=6)\n",
    "relevant_info = [m['section'] + \": \" + d for d, m in zip(results['documents'][0], results['metadatas'][0])]\n",
    "resume_context = \"\\n\".join(relevant_info)\n",
    "\n",
    "# --- Step 3: Cover Letter Prompt Template ---\n",
    "prompt_coverletter = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### JOB TITLE:\n",
    "    {job_title}\n",
    "\n",
    "    ### JOB DESCRIPTION:\n",
    "    {job_description}\n",
    "    \n",
    "    ### RESUME CONTEXT:\n",
    "    {resume_context}\n",
    "    \n",
    "    ### INSTRUCTION:\n",
    "    Write a professional cover letter tailored for the above job title and description.\n",
    "    Match and highlight relevant experience and skills from the resume context.\n",
    "    Keep the tone formal and enthusiastic.\n",
    "    Avoid generic clichés. Focus on measurable impacts, technologies used, and specific experiences.\n",
    "    Address it to \"Hiring Manager\".\n",
    "    Sign off with \"Sincerely, [Your Name]\".\n",
    "\n",
    "    ### COVER LETTER (NO PREAMBLE):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# --- Step 4: Invoke the Chain ---\n",
    "chain_coverletter = prompt_coverletter | llm  # Assumes `llm` is your language model\n",
    "res = chain_coverletter.invoke({\n",
    "    \"job_title\": job['Software Engineer II, Platform']['role'],\n",
    "    \"job_description\": job['Software Engineer II, Platform']['description'],\n",
    "    \"resume_context\": resume_context\n",
    "})\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fa2bb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\siria\\downloads\\cold-email-generator\\.venv\\lib\\site-packages (from beautifulsoup4->bs4) (4.14.1)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "\n",
      "   ---------------------------------------- 0/3 [soupsieve]\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ---------------------------------------- 3/3 [bs4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.4 bs4-0.0.2 soupsieve-2.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119ac9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting Pillow>=9.1 (from pdfplumber)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\siria\\downloads\\cold-email-generator\\.venv\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.6/5.6 MB 43.5 MB/s eta 0:00:00\n",
      "Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/3.4 MB 38.6 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl (182 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 58.2 MB/s eta 0:00:00\n",
      "Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 60.9 MB/s eta 0:00:00\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pypdfium2, pycparser, Pillow, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "\n",
      "   ---------------------------------------- 0/7 [pypdfium2]\n",
      "   ---------------------------------------- 0/7 [pypdfium2]\n",
      "   ---------------------------------------- 0/7 [pypdfium2]\n",
      "   ---------------------------------------- 0/7 [pypdfium2]\n",
      "   ---------------------------------------- 0/7 [pypdfium2]\n",
      "   ----- ---------------------------------- 1/7 [pycparser]\n",
      "   ----- ---------------------------------- 1/7 [pycparser]\n",
      "   ----- ---------------------------------- 1/7 [pycparser]\n",
      "   ----- ---------------------------------- 1/7 [pycparser]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------- ---------------------------- 2/7 [Pillow]\n",
      "   ----------------- ---------------------- 3/7 [cffi]\n",
      "   ----------------- ---------------------- 3/7 [cffi]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------- ----------------- 4/7 [cryptography]\n",
      "   ---------------------------- ----------- 5/7 [pdfminer.six]\n",
      "   ---------------------------- ----------- 5/7 [pdfminer.six]\n",
      "   ---------------------------- ----------- 5/7 [pdfminer.six]\n",
      "   ---------------------------- ----------- 5/7 [pdfminer.six]\n",
      "   ---------------------------- ----------- 5/7 [pdfminer.six]\n",
      "   ---------------------------- ----------- 5/7 [pdfminer.six]\n",
      "   ---------------------------------- ----- 6/7 [pdfplumber]\n",
      "   ---------------------------------- ----- 6/7 [pdfplumber]\n",
      "   ---------------------------------- ----- 6/7 [pdfplumber]\n",
      "   ---------------------------------------- 7/7 [pdfplumber]\n",
      "\n",
      "Successfully installed Pillow-11.3.0 cffi-1.17.1 cryptography-45.0.5 pdfminer.six-20250506 pdfplumber-0.11.7 pycparser-2.22 pypdfium2-4.30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
